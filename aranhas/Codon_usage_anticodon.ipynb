{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Codon Usage and tRNA Anticodon\n",
    "\n",
    "Using a list of genbank files as input, this script:\n",
    "\n",
    "- [x] Extracts all its CDS's\n",
    "- [x] Calculates codon usage\n",
    "\n",
    "---\n",
    "\n",
    "- [x] Converts each sequence to fasta (or only the concatenated tRNAs)\n",
    "- [x] Uses the trnascan-SE to identify the anticodon\n",
    "\n",
    "---\n",
    "\n",
    "Generates an excel spreadsheet, containing the following fields:\n",
    "\n",
    "- [x] Species\n",
    "\n",
    "- [x] Translation table\n",
    "\n",
    "- [x] Aminoacid (Three-letter code)\n",
    "\n",
    "- [x] Codon for that aminoacid\n",
    "\n",
    "- [ ] Has anticodon in mito tRNAs? YES or EMPTY VALUE\n",
    "\n",
    "- [x] Number of occurrences of that codon in the genes \n",
    "\n",
    "- [x] \\1000 - (number_of_codon_occurences / total number of aa - including start_stop_codons) * 1000\n",
    "\n",
    "- [x] Fraction: codon occurences / sum of all codon occurences for that aa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import everything we need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "import pandas\n",
    "from Bio.Seq import Seq\n",
    "#from Bio.Alphabet import generic_dna\n",
    "from Bio.Data import CodonTable\n",
    "from Bio.SeqUtils import seq3\n",
    "import subprocess, os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order for this script to work, you have to execute it from within the directory with the genbank files or change the working directory using  **os.chdir(\"path/to/directory/\")**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to add all gb files **(no .gbk allowed!)** to a list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "genbank = glob.glob(\"./gbks/*.gb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#genbank = !ls *gb\n",
    "#genbank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./gbks/Tetragnatha_nitens_NC_028068.1.gb'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genbank[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# trnascan\n",
    "There are files for the different genetic tables in /home/gabriel/bioinfo/anaconda3/lib/tRNAscan-SE/gcode/gcode.vertmito.\n",
    "Maybe looking at this will give me some ideas on how to run the trnascan for other tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genbank_to_fasta(genbank):\n",
    "    record = SeqIO.read(genbank, \"genbank\")\n",
    "    species = record.annotations.get(\"organism\").replace(\" \", \"_\")\n",
    "    seq = record.seq\n",
    "    fasta = \">{}\\n{}\".format(species, seq)\n",
    "    return(fasta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_trnascan(genbank):\n",
    "    fasta = genbank_to_fasta(genbank)\n",
    "    with open(\"tempfile\", \"w+\") as tempfile:\n",
    "        tempfile.write(fasta)\n",
    "        trnascan = subprocess.Popen([\"tRNAscan-SE\", \"-M\", \"mammal\", \"tempfile\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "        trnascan.wait()\n",
    "        output, error = trnascan.communicate()\n",
    "        os.remove(\"tempfile\")\n",
    "        return(output.decode().split(\"\\n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trnascan_se_anticodon_parser(trnascan_output, species):\n",
    "    anticodon_dict = dict()\n",
    "    for i in trnascan_output:\n",
    "         if i.startswith(species):\n",
    "                i = i.split(\"\\t\")\n",
    "                aminoacid = i[4].strip()\n",
    "                anticodon = i[5].strip()\n",
    "                if aminoacid not in anticodon_dict:\n",
    "                    anticodon_dict[aminoacid] = list()\n",
    "                anticodon_dict.get(aminoacid).append(anticodon)\n",
    "                \n",
    "    return(anticodon_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "We also have to calculate codon usage for all CDSs. In order to do so, we first need to extract all CDS from the genbank file, make sure that all sequences are multiple of 3 (or otherwise adding \"A\" residues from poly-A tail to complete the codon) and concatenate the CDS's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_CDS(genbank):\n",
    "    CDS_list = list()\n",
    "    for record in SeqIO.parse(genbank, \"genbank\"):\n",
    "        accession = record.id\n",
    "        species_name = record.annotations.get(\"organism\").replace(\" \", \"_\")\n",
    "        for FEATURE in record.features:\n",
    "            if FEATURE.type == \"CDS\":\n",
    "                gene = FEATURE.qualifiers.get(\"gene\")[0]\n",
    "                sequence = FEATURE.location.extract(record).seq\n",
    "                CDS_list.append([accession, species_name, gene, sequence])\n",
    "    return(CDS_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_truncated(coding_list):\n",
    "    not_trunc_cds_list = list()\n",
    "    for i in coding_list:\n",
    "        truncated_nucs = len(i[3]) % 3\n",
    "        if truncated_nucs:\n",
    "            missing_nucs = 3 - truncated_nucs\n",
    "            #REWRITE THIS IN ORDER TO JUST ADD THE RESIDUES FROM THE POLY-A TAIL - DONE\n",
    "            #print(\"Truncated stop codon for gene {}\".format(i[2]))\n",
    "            #print(\"Before:{} truncated_nucs\".format(len(i[3]) % 3))\n",
    "            #print(\"Before: {}\".format(i[3]))\n",
    "            i[3] = i[3] + (missing_nucs * 'A')\n",
    "            #print()\n",
    "            #print(\"After: {}\".format(i[3]))\n",
    "            #print(\"After:{} truncated_nucs\".format(len(i[3]) % 3))\n",
    "            not_trunc_cds_list.append(i)\n",
    "        else:\n",
    "            not_trunc_cds_list.append(i)\n",
    "    return(not_trunc_cds_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEXT STEP:\n",
    "\n",
    "Take a look at the \"CAI.py\" file and use it as a reference to write a function that counts codons for any genetic code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adapted from CAI.py:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from itertools import chain\n",
    "#from Bio.Data import CodonTable\n",
    "#from collections import Counter\n",
    "#from Bio.SeqUtils import seq3\n",
    "\n",
    "# get rid of Biopython warning\n",
    "#import warnings\n",
    "#from Bio import BiopythonWarning\n",
    "\n",
    "#warnings.simplefilter(\"ignore\", BiopythonWarning)\n",
    "\n",
    "\n",
    "def set_ncbi_genetic_codes():\n",
    "\n",
    "\n",
    "    ncbi_genetic_codes = {}\n",
    "    for table, codes in CodonTable.unambiguous_dna_by_id.items():\n",
    "        \n",
    "        # invert the genetic code dictionary to map each amino acid to its codons\n",
    "        # create dictionary of synonymous codons;\n",
    "        # Example: {'Phe': ['TTT', 'TTC'], ..., 'End': ['TAA', 'TAG', 'TGA']}\n",
    "        codons_for_amino_acid = {}\n",
    "        for codon, amino_acid in codes.forward_table.items():\n",
    "            amino_acid = seq3(amino_acid)\n",
    "            codons_for_amino_acid[amino_acid] = codons_for_amino_acid.get(amino_acid, [])\n",
    "            codons_for_amino_acid[amino_acid].append(codon)\n",
    "        #Adding the stop codons\n",
    "        codons_for_amino_acid[\"End\"] = CodonTable.unambiguous_dna_by_id[table].stop_codons\n",
    "        \n",
    "        #create dictionary of synonymous codons for each genetic table;\n",
    "        ncbi_genetic_codes[table] = codons_for_amino_acid\n",
    "        \n",
    "    return(ncbi_genetic_codes)\n",
    "\n",
    "#codon_tables = set_ncbi_genetic_codes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(codon_tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, all tables have exactly 64 codons, and 20 aminoacids (20 + stop) as expected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for table in codon_tables.keys():\\n    codons = 0\\n    for aa in codon_tables[table]:\\n        codons += len(codon_tables[table][aa])\\n    print(\"Table number: {} \\t Number of codons: {} \\t Aminoacids: {}\".format          (table, codons , len(codon_tables[table].keys())))'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''for table in codon_tables.keys():\n",
    "    codons = 0\n",
    "    for aa in codon_tables[table]:\n",
    "        codons += len(codon_tables[table][aa])\n",
    "    print(\"Table number: {} \\t Number of codons: {} \\t Aminoacids: {}\".format\\\n",
    "          (table, codons , len(codon_tables[table].keys())))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_codons(sequence):\n",
    "    from itertools import product\n",
    "    \n",
    "    #create dictionary with each codon for counting (list comprehension inside dictionary comprehension)\n",
    "    codon_count_dict = {codon: 0 for codon in \n",
    "                  [''.join(i) for i in product(\"ATCG\", repeat=3)]}\n",
    "    \n",
    "    if len(sequence) % 3 != 0:\n",
    "        raise ValueError(\"Input sequence not divisible by three\")\n",
    "    for n, i in enumerate(range(0, len(sequence), 3), 1):\n",
    "        codon = str(sequence[i:i+3].upper())\n",
    "        if codon not in codon_count_dict.keys():\n",
    "            raise ValueError(\"This sequence probably has ambiguous IUPAC characters. \" \n",
    "                             \"Please submit sequences containing only A, T, G or C.\")\n",
    "        codon_count_dict[codon] += 1\n",
    "        \n",
    "    return(codon_count_dict)\n",
    "\n",
    "#print(count_codons(concat))\n",
    "\n",
    "#codon_count = count_codons(concat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEXT STEP:\n",
    "Calculate all metrics associated with codon usage AND map it to its corresponding aminoacids, species, etc.\n",
    "Accomodate this data into a dataframe and plot it into an excel file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def per_thousand(codon_count_dict):\n",
    "    total_codon_number = sum(codon_count_dict.values())\n",
    "    per_thousand = {codon: round((count/total_codon_number)*1000, 2) \n",
    "                    for codon, count in codon_count_dict.items()}\n",
    "    return(per_thousand)    \n",
    "\n",
    "#per_thousand = per_thousand(codon_count)\n",
    "#print(per_thousand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_genetic_code(genbank):\n",
    "    record = SeqIO.read(genbank, \"genbank\")\n",
    "    genetic_code = set()\n",
    "    for i in record.features:\n",
    "        if i.type == \"CDS\":\n",
    "            genetic_code.add(i.qualifiers.get(\"transl_table\")[0])\n",
    "    if len(genetic_code) != 1:\n",
    "        raise ValueError(\"The {} file has more than one genetic code for its CDS's: {} \" \n",
    "                             \"Please correct that before submiting\".format(genbank, genetic_code))\n",
    "    return(int(list(genetic_code)[0]))\n",
    "    \n",
    "#genetic_code = identify_genetic_code(genbank[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(codon_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fraction(codon_count_dict, transl_table):\n",
    "    fraction = dict()\n",
    "    for codon_list in transl_table.values():\n",
    "        codon_occurrences_per_aa = 0\n",
    "        for codon in codon_list:\n",
    "            codon_occurrences_per_aa += codon_count_dict[codon]\n",
    "        for codon in codon_list:\n",
    "            fraction[codon] = round(codon_count_dict[codon]/codon_occurrences_per_aa, 2)\n",
    "    return(fraction)\n",
    "\n",
    "#fraction = fraction(codon_count, codon_tables[genetic_code])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trnascan_se_parser(trnascan_output, sequence_name):\n",
    "    aminoacid = list()\n",
    "    anticodon = list()\n",
    "    for i in trnascan_output:\n",
    "         if i.startswith(sequence_name):\n",
    "                i = i.split(\"\\t\")\n",
    "                aminoacid.append(i[4].strip())\n",
    "                anticodon.append(i[5].strip())\n",
    "    trnascan_dict = {sequence_name: {i[0]: i[1] for i in zip(aminoacid, anticodon)}}\n",
    "    return(trnascan_dict)\n",
    "        \n",
    "\n",
    "#trna_scan_parse = trnascan_se_parser(trnascan_output, species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(trna_scan_parse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEXT:\n",
    "Create main function and put all data into a dataframe.\n",
    "**TIP:** In the main function, put the codon usage functions first, then the anticodon.\n",
    "Structure chosen for the dataframe: list of dictionaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'excel_dict = [\\n    {\\'species\\': species_name, \\'transl_table\\': translat_table,\\n     \\'aminoacid\\': Three-letter aa, \"Has anticodon in mito?\": Yes or no,\\n    \\'Number of codon occurences\\': number of codons, \\'/1000\\': per_thousand,\\n    \\'Fraction\\': fraction}\\n]'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#template:\n",
    "\n",
    "'''excel_dict = [\n",
    "    {'species': species_name, 'transl_table': translat_table,\n",
    "     'aminoacid': Three-letter aa, \"Has anticodon in mito?\": Yes or no,\n",
    "    'Number of codon occurences': number of codons, '/1000': per_thousand,\n",
    "    'Fraction': fraction}\n",
    "]'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x] Species\n",
    "\n",
    "- [x] Translation table\n",
    "\n",
    "- [x] Aminoacid (Three-letter code)\n",
    "\n",
    "- [x] Codon for that aminoacid\n",
    "\n",
    "- [ ] Has anticodon in mito tRNAs? YES or EMPTY VALUE\n",
    "\n",
    "- [x] Number of occurrences of that codon in the genes \n",
    "\n",
    "- [x] \\1000 - (number_of_codon_occurences / total number of aa - including start_stop_codons) * 1000\n",
    "\n",
    "- [x] Fraction: codon occurences / sum of all codon occurences for that aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenate_CDS(not_trunc):\n",
    "    concat = ''\n",
    "    for i in not_trunc:\n",
    "        concat += i[3]\n",
    "    return concat\n",
    "\n",
    "def species_name(not_trunc):\n",
    "    species = set()\n",
    "    for i in not_trunc:\n",
    "        species.add(i[1])\n",
    "    if len(species) == 1:\n",
    "        return list(species)[0]\n",
    "    else:\n",
    "        raise ValueError(\"More than one organism for a single genbank file?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def invert_codon_table(codon_table):\n",
    "    new_codon_table = dict()\n",
    "    for key in codon_table.keys():\n",
    "        #print(key)\n",
    "        for codon in codon_table.get(key):\n",
    "            new_codon_table[codon] = key\n",
    "            \n",
    "    return(new_codon_table)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_anticodon(codon, aa_3letter, anticodon_dict):\n",
    "    #print(aa_3letter)\n",
    "    if aa_3letter in anticodon_dict.keys():\n",
    "        for value in anticodon_dict.get(aa_3letter):\n",
    "            anticodon = Seq(value, generic_dna)\n",
    "            if codon == str(anticodon.reverse_complement()):\n",
    "                return(value)\n",
    "    return(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_parser(species, genetic_code, inverse_codon_table, \n",
    "                     codon_count_dict, per_thousand_dict, fraction_dict, \n",
    "                     anticodon_dict):\n",
    "    fields = ['Species', 'Translation Table', 'Aminoacid', 'Codon', 'Anticodon', \n",
    "                  'Number of Codon Occurences', '/1000', 'Fraction']\n",
    "    dataframe_dict = {k : list() for k in fields}\n",
    "    for codon, fraction in fraction_dict.items():\n",
    "        dataframe_dict.get('Species').append(species)\n",
    "        dataframe_dict.get('Translation Table').append(genetic_code)\n",
    "        aa_3letter = inverse_codon_table.get(codon)\n",
    "        dataframe_dict.get('Aminoacid').append(aa_3letter)\n",
    "        dataframe_dict.get('Codon').append(codon)\n",
    "        #dataframe_dict.get('Anticodon').append(has_anticodon(codon, aa_3letter, anticodon_dict))\n",
    "        dataframe_dict.get('Number of Codon Occurences').append(codon_count_dict.get(codon))\n",
    "        dataframe_dict.get('/1000').append(per_thousand_dict.get(codon))\n",
    "        dataframe_dict.get('Fraction').append(fraction)\n",
    "    return(dataframe_dict)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataframe(parsed_data):\n",
    "    codon_usage = pandas.DataFrame(parsed_data)\n",
    "    return(codon_usage)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_dataframes(dataframe_data):\n",
    "    dataframes = []\n",
    "    for i in dataframe_data.keys():\n",
    "        dataframes.append(dataframe_data.get(i))\n",
    "    final_dataframe = pandas.concat(dataframes)\n",
    "    return(final_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_dataframe_to_excel(final_dataframe):\n",
    "    final_dataframe.to_excel(\"Codon_usage.xlsx\", index=False, sheet_name=\"codon_usage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running analysis for ./gbks/Tetragnatha_nitens_NC_028068.1.gb\n",
      "./gbks/Tetragnatha_nitens_NC_028068.1.gb analysis failed\n",
      "Running analysis for ./gbks/Songthela_hangzhouensis_NC_005924.1.gb\n",
      "./gbks/Songthela_hangzhouensis_NC_005924.1.gb analysis failed\n",
      "Running analysis for ./gbks/Hypochilus_thorelli_NC_010777.1.gb\n",
      "./gbks/Hypochilus_thorelli_NC_010777.1.gb analysis failed\n",
      "Running analysis for ./gbks/Neoscona_adianta_NC_029756.1.gb\n",
      "./gbks/Neoscona_adianta_NC_029756.1.gb analysis failed\n",
      "Running analysis for ./gbks/Telamonia_vlijmi_NC_024287.1.gb\n",
      "./gbks/Telamonia_vlijmi_NC_024287.1.gb analysis failed\n",
      "Running analysis for ./gbks/Argiope_perforata_NC_044695.1.gb\n",
      "./gbks/Argiope_perforata_NC_044695.1.gb analysis failed\n",
      "Running analysis for ./gbks/Phyxioschema_suthepium_NC_020322.1.gb\n",
      "./gbks/Phyxioschema_suthepium_NC_020322.1.gb analysis failed\n",
      "Running analysis for ./gbks/Selenops_bursarius_NC_024878.1.gb\n",
      "./gbks/Selenops_bursarius_NC_024878.1.gb analysis failed\n",
      "Running analysis for ./gbks/Agelena_silvatica_NC_033971.1.gb\n",
      "./gbks/Agelena_silvatica_NC_033971.1.gb analysis failed\n",
      "Running analysis for ./gbks/Epeus_alboguttatus_NC_042829.1.gb\n",
      "./gbks/Epeus_alboguttatus_NC_042829.1.gb analysis failed\n",
      "Running analysis for ./gbks/Haplopelma_schmidti_NC_005925.1.gb\n",
      "./gbks/Haplopelma_schmidti_NC_005925.1.gb analysis failed\n",
      "Running analysis for ./gbks/Cyclosa_japonica_NC_044696.1.gb\n",
      "./gbks/Cyclosa_japonica_NC_044696.1.gb analysis failed\n",
      "Running analysis for ./gbks/Tetragnatha_maxillosa_NC_025775.1.gb\n",
      "./gbks/Tetragnatha_maxillosa_NC_025775.1.gb analysis failed\n",
      "Running analysis for ./gbks/Mesabolivar_sp._ITV1036I1_NC_040859.1.gb\n",
      "./gbks/Mesabolivar_sp._ITV1036I1_NC_040859.1.gb analysis failed\n",
      "Running analysis for ./gbks/Wadicosa_fidelis_NC_026123.1.gb\n",
      "./gbks/Wadicosa_fidelis_NC_026123.1.gb analysis failed\n",
      "Running analysis for ./gbks/Liphistius_erawan_NC_020323.1.gb\n",
      "./gbks/Liphistius_erawan_NC_020323.1.gb analysis failed\n",
      "Running analysis for ./gbks/Neoscona_scylla_NC_044101.1.gb\n",
      "./gbks/Neoscona_scylla_NC_044101.1.gb analysis failed\n",
      "Running analysis for ./gbks/Carrhotus_xanthogramma_NC_027492.1.gb\n",
      "./gbks/Carrhotus_xanthogramma_NC_027492.1.gb analysis failed\n",
      "Running analysis for ./gbks/Araneus_ventricosus_NC_025634.1.gb\n",
      "./gbks/Araneus_ventricosus_NC_025634.1.gb analysis failed\n",
      "Running analysis for ./gbks/Pholcus_phalangioides_NC_020324.1.gb\n",
      "./gbks/Pholcus_phalangioides_NC_020324.1.gb analysis failed\n",
      "Running analysis for ./gbks/Hypsosinga_pygmaea_NC_028078.1.gb\n",
      "./gbks/Hypsosinga_pygmaea_NC_028078.1.gb analysis failed\n",
      "Running analysis for ./gbks/pho_pertyi_FINAL.gb\n",
      "./gbks/pho_pertyi_FINAL.gb analysis failed\n",
      "Running analysis for ./gbks/Neoscona_nautica_NC_029755.1.gb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel/miniconda3/lib/python3.9/site-packages/Bio/GenBank/__init__.py:1380: BiopythonParserWarning: Expected sequence length 14876, found 14877 (XXXXXXXX).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./gbks/Neoscona_nautica_NC_029755.1.gb analysis failed\n",
      "Running analysis for ./gbks/Argyroneta_aquatica_NC_026863.1.gb\n",
      "./gbks/Argyroneta_aquatica_NC_026863.1.gb analysis failed\n",
      "Running analysis for ./gbks/Cyrtarachne_nagasakiensis_NC_028077.1.gb\n",
      "./gbks/Cyrtarachne_nagasakiensis_NC_028077.1.gb analysis failed\n",
      "Running analysis for ./gbks/Oxyopes_sertatus_NC_025224.1.gb\n",
      "./gbks/Oxyopes_sertatus_NC_025224.1.gb analysis failed\n",
      "Running analysis for ./gbks/Plexippus_paykulli_NC_024877.1.gb\n",
      "./gbks/Plexippus_paykulli_NC_024877.1.gb analysis failed\n",
      "Running analysis for ./gbks/Parachtes_romandiolae_NC_044099.1.gb\n",
      "./gbks/Parachtes_romandiolae_NC_044099.1.gb analysis failed\n",
      "Running analysis for ./gbks/Trichonephila_clavata_NC_008063.1.gb\n",
      "./gbks/Trichonephila_clavata_NC_008063.1.gb analysis failed\n",
      "Running analysis for ./gbks/Argiope_bruennichi_NC_024281.1.gb\n",
      "./gbks/Argiope_bruennichi_NC_024281.1.gb analysis failed\n",
      "Running analysis for ./gbks/Oxytate_striatipes_NC_025557.1.gb\n",
      "./gbks/Oxytate_striatipes_NC_025557.1.gb analysis failed\n",
      "Running analysis for ./gbks/Cyriopagopus_hainanus_NC_053738.1.gb\n",
      "./gbks/Cyriopagopus_hainanus_NC_053738.1.gb analysis failed\n",
      "Running analysis for ./gbks/Mesabolivar_sp._ITV1036I3_NC_040861.1.gb\n",
      "./gbks/Mesabolivar_sp._ITV1036I3_NC_040861.1.gb analysis failed\n",
      "Running analysis for ./gbks/l_curacaviensis.gb\n",
      "./gbks/l_curacaviensis.gb analysis failed\n",
      "Running analysis for ./gbks/Neoscona_multiplicans_NC_044653.1.gb\n",
      "./gbks/Neoscona_multiplicans_NC_044653.1.gb analysis failed\n",
      "Running analysis for ./gbks/Pardosa_laura_NC_025223.1.gb\n",
      "./gbks/Pardosa_laura_NC_025223.1.gb analysis failed\n",
      "Running analysis for ./gbks/Habronattus_oregonensis_NC_005942.1.gb\n",
      "./gbks/Habronattus_oregonensis_NC_005942.1.gb analysis failed\n",
      "Running analysis for ./gbks/Oxyopes_licenti_NC_053648.1.gb\n",
      "./gbks/Oxyopes_licenti_NC_053648.1.gb analysis failed\n",
      "Running analysis for ./gbks/loxosceles_similis.gb\n",
      "./gbks/loxosceles_similis.gb analysis failed\n",
      "Running analysis for ./gbks/lox_laeta_FINAL.gb\n",
      "./gbks/lox_laeta_FINAL.gb analysis failed\n",
      "Running analysis for ./gbks/Cyclosa_argenteoalba_NC_027682.1.gb\n",
      "./gbks/Cyclosa_argenteoalba_NC_027682.1.gb analysis failed\n",
      "Running analysis for ./gbks/Neoscona_theisi_NC_026290.1.gb\n",
      "./gbks/Neoscona_theisi_NC_026290.1.gb analysis failed\n",
      "Running analysis for ./gbks/Harpactocrates_apennicola_NC_044081.1.gb\n",
      "./gbks/Harpactocrates_apennicola_NC_044081.1.gb analysis failed\n",
      "Running analysis for ./gbks/lat_geo_FINAL.gb\n",
      "./gbks/lat_geo_FINAL.gb analysis failed\n",
      "Running analysis for ./gbks/Oxyopes_hupingensis_NC_046736.1.gb\n",
      "./gbks/Oxyopes_hupingensis_NC_046736.1.gb analysis failed\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6522/1736992134.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mexcel_output_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfields\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m '''\n\u001b[0;32m---> 56\u001b[0;31m \u001b[0mmain_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenbank\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_6522/1736992134.py\u001b[0m in \u001b[0;36mmain_func\u001b[0;34m(genbank_list)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mdataframe_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mfinal_dataframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconcat_dataframes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataframe_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_dataframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_6522/3029095696.py\u001b[0m in \u001b[0;36mconcat_dataframes\u001b[0;34m(dataframe_data)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataframe_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mdataframes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataframe_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mfinal_dataframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataframes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_dataframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    292\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIndexes\u001b[0m \u001b[0mhave\u001b[0m \u001b[0moverlapping\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m     \"\"\"\n\u001b[0;32m--> 294\u001b[0;31m     op = _Concatenator(\n\u001b[0m\u001b[1;32m    295\u001b[0m         \u001b[0mobjs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m         \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No objects to concatenate\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkeys\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: No objects to concatenate"
     ]
    }
   ],
   "source": [
    "def main_func(genbank_list):\n",
    "    codon_tables = set_ncbi_genetic_codes()\n",
    "    dataframe_data = dict()\n",
    "    for index, genbank in enumerate(genbank_list, 1):\n",
    "        print(\"Running analysis for {}\".format(genbank))\n",
    "        try:\n",
    "            not_trunc = fix_truncated(extract_CDS(genbank))\n",
    "        \n",
    "            cds_concat = concatenate_CDS(not_trunc)\n",
    "        \n",
    "            species = species_name(not_trunc)\n",
    "        \n",
    "            codon_count_dict = count_codons(cds_concat)\n",
    "        \n",
    "            per_thousand_dict = per_thousand(codon_count_dict)\n",
    "        \n",
    "            genetic_code = identify_genetic_code(genbank)\n",
    "                \n",
    "            fraction_dict = fraction(codon_count_dict, codon_tables[genetic_code])\n",
    "        \n",
    "            trnascan_output = run_trnascan(genbank)\n",
    "        \n",
    "            anticodon_dict = trnascan_se_anticodon_parser(trnascan_output, species)\n",
    "        \n",
    "            inverse_codon_table = invert_codon_table(codon_tables[genetic_code])\n",
    "        \n",
    "            parsed_data = dataframe_parser(species, genetic_code, inverse_codon_table, \n",
    "                                           codon_count_dict, per_thousand_dict, fraction_dict, \n",
    "                                           anticodon_dict)\n",
    "        except:\n",
    "            print(\"{} analysis failed\".format(genbank))\n",
    "            continue\n",
    "        \n",
    "        dataframe_data[index] = create_dataframe(parsed_data)\n",
    "        \n",
    "    final_dataframe = concat_dataframes(dataframe_data)\n",
    "    print(final_dataframe)\n",
    "    \n",
    "    export_dataframe_to_excel(final_dataframe)\n",
    "        \n",
    "        #print(anticodon_dict.keys())\n",
    "        #print(len(anticodon_dict.keys()))\n",
    "        #print(set(inverse_codon_table.values()))\n",
    "        #print(len(set(inverse_codon_table.values())))\n",
    "        #print(species, type(species))\n",
    "        #print(not_trunc)\n",
    "        #print(cds_concat)\n",
    "        #print(\"per_thousand_dict:\\n{}\".format(per_thousand_dict))\n",
    "        #print(\"codon_count_dict:\\n{}\".format(codon_count_dict))\n",
    "        #print(\"genetic_code {}:\\n{}\".format(genetic_code, codon_tables[genetic_code]))    \n",
    "        #print(\"fraction_dict:\\n{}\".format(fraction_dict))\n",
    "'''        fields = ['species', 'transl_table', 'aminoacid', \"Anticodon\", \n",
    "                  'Number of codon occurences', '/1000', 'Fraction']\n",
    "        excel_output_dict = {k : list() for k in fields}\n",
    "'''\n",
    "main_func(genbank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Just me messing around with codon tables and such"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Phe': ['TTT', 'TTC'], 'Leu': ['TTA', 'TTG', 'CTT', 'CTC', 'CTA', 'CTG'], 'Ser': ['TCT', 'TCC', 'TCA', 'TCG', 'AGT', 'AGC'], 'Tyr': ['TAT', 'TAC'], 'Cys': ['TGT', 'TGC'], 'Trp': ['TGA', 'TGG'], 'Pro': ['CCT', 'CCC', 'CCA', 'CCG'], 'His': ['CAT', 'CAC'], 'Gln': ['CAA', 'CAG'], 'Arg': ['CGT', 'CGC', 'CGA', 'CGG'], 'Ile': ['ATT', 'ATC'], 'Met': ['ATA', 'ATG'], 'Thr': ['ACT', 'ACC', 'ACA', 'ACG'], 'Asn': ['AAT', 'AAC'], 'Lys': ['AAA', 'AAG'], 'Val': ['GTT', 'GTC', 'GTA', 'GTG'], 'Ala': ['GCT', 'GCC', 'GCA', 'GCG'], 'Asp': ['GAT', 'GAC'], 'Glu': ['GAA', 'GAG'], 'Gly': ['GGT', 'GGC', 'GGA', 'GGG'], 'End': ['TAA', 'TAG', 'AGA', 'AGG']}\n"
     ]
    }
   ],
   "source": [
    "codon_tables = set_ncbi_genetic_codes()\n",
    "\n",
    "print(codon_tables[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allochrocebus_lhoesti_NC_023962.1.gb\n"
     ]
    }
   ],
   "source": [
    "print(genbank[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = ['species', 'transl_table', 'aminoacid', \"Anticodon\", \n",
    "                  'Number of codon occurences', '/1000', 'Fraction']\n",
    "excel_output_dict = {k : list() for k in fields}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TTT 0.45\n",
      "TTC 0.55\n",
      "TTA 0.16\n",
      "TTG 0.03\n",
      "CTT 0.15\n",
      "CTC 0.16\n",
      "CTA 0.45\n",
      "CTG 0.04\n",
      "TCT 0.19\n",
      "TCC 0.29\n",
      "TCA 0.28\n",
      "TCG 0.03\n",
      "AGT 0.06\n",
      "AGC 0.14\n",
      "TAT 0.4\n",
      "TAC 0.6\n",
      "TGT 0.38\n",
      "TGC 0.62\n",
      "TGA 0.91\n",
      "TGG 0.09\n",
      "CCT 0.22\n",
      "CCC 0.4\n",
      "CCA 0.37\n",
      "CCG 0.02\n",
      "CAT 0.34\n",
      "CAC 0.66\n",
      "CAA 0.95\n",
      "CAG 0.05\n",
      "CGT 0.17\n",
      "CGC 0.32\n",
      "CGA 0.45\n",
      "CGG 0.06\n",
      "ATT 0.46\n",
      "ATC 0.54\n",
      "ATA 0.85\n",
      "ATG 0.15\n",
      "ACT 0.21\n",
      "ACC 0.33\n",
      "ACA 0.44\n",
      "ACG 0.02\n",
      "AAT 0.33\n",
      "AAC 0.67\n",
      "AAA 0.93\n",
      "AAG 0.07\n",
      "GTT 0.23\n",
      "GTC 0.29\n",
      "GTA 0.4\n",
      "GTG 0.08\n",
      "GCT 0.26\n",
      "GCC 0.43\n",
      "GCA 0.3\n",
      "GCG 0.01\n",
      "GAT 0.45\n",
      "GAC 0.55\n",
      "GAA 0.79\n",
      "GAG 0.21\n",
      "GGT 0.22\n",
      "GGC 0.34\n",
      "GGA 0.32\n",
      "GGG 0.12\n",
      "TAA 0.85\n",
      "TAG 0.08\n",
      "AGA 0.0\n",
      "AGG 0.08\n"
     ]
    }
   ],
   "source": [
    "for key, value in fraction_dict.items():\n",
    "    print(key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls.append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "amino_acid = seq3(\"F\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Phe'"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amino_acid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
